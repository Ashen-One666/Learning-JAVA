## 登录
### 基于Session登录
#### 流程
- 发送验证码
- 验证码登录、注册
- 校验登录状态
### 基于redis
### 基于jwt
- 客户端将jwt存在local storage中（jwt经过编码后非常长，cookie不够存）
### 无状态登录和有状态登录优缺点

## 缓存穿透，击穿，雪崩
### 缓存穿透
解决方案：
- 缓存空值
- 布隆过滤器
  - 计数布隆过滤器：将位数组替换为计数数组，插入时递增计数，删除时递减计数（内存开销大）
  - 重建过滤器
  - 布谷鸟过滤器
- 增强id复杂度
- 做好数据格式校验
- ip限制

### 缓存雪崩
- 随机ttl
- 提高redis可用性（集群）
- 多级缓存：redis + Caffeine
  - Caffeine：本地缓存库，存储在JVM堆内存中
    - 缓存淘汰策略
      - 基于频率：TinyLFU 机制，自动淘汰低频访问的数据
      - 基于时间
      - 基于大小
    - 数据结构：基于ConcurrentHashMap，实现高并发读写优化
    - 支持异步写入缓存
    - 支持设置过期时间
    - 防止OOM： 合理设置大小上限 + 设置软引用、弱引用
  - 多级缓存读写策略：
    - 读： 先读Caffeine，再读redis，都没有再读数据库并写回
    - 写： 先更新数据库，再删两个缓存数据

### 缓存击穿
- 互斥锁
- 逻辑过期

## 查询商铺
### SQL深分页优化



## 优惠券秒杀 + 异步一人一单
- 秒杀考虑3个问题：
  - 秒杀是否开始或结束
  - 库存是否充足
  - 是否一人一单
- 实现过程中的重点：
  - 使用乐观锁解决库存超卖问题（即在修改数据库库存时判断当前库存是否大于0）
  - 使用基于Redisson的分布式锁解决集群环境下的并发问题和Redis的不可重入问题
  - 使用RabbitMQ实现异步秒杀，优化秒杀操作的性能
- 注意点：
  - 如果使用异步秒杀，则秒杀不需要分布式锁或者乐观锁
  - 分布式锁应用场景：
    - 双写一致性：异步线程更新数据库时会使用到

### 业务需求
- 商品不少卖
- 商品不超卖
- 下单响应快
- 数据一致性

### 重复下单
- 场景：
  - 用户点击过快
  - 网络延迟，用户重复提交
  - 网络爬虫
- 解决方案：
  - 前端拦截（按钮变灰） + redis防止用户重复下单
  - 防止恶意攻击：一分钟下单超过10次加入临时黑名单（redis的list存储）

### 全局id生成器
- 为什么需要：单表不够存订单，要分库分表
- 要求：唯一性 + 高性能 + 高可用 + 安全性（不包含敏感信息） + 递增性
- 生成器方案：
  - 数据库自增
  - redis自增
  - uuid
  - 雪花算法
  - zookeeper
  - id生成工具：百度UIDGenerator 美团leaf
  - 最终方案：1位符号位 + 31位时间戳（当前UTC时间-起始时间） + 32位序列号（秒内计数器）

### 同步和异步解决 秒杀 + 一人一单
#### 同步秒杀：
- 乐观锁解决库存超卖：单纯对于mysql的操作（大于0 或 版本号）
  - ```sql
    UPDATE product 
    SET stock = stock - 1
    WHERE id = 1 AND stock > 0;
    ```
  - 缺点：是基于数据库的，当并发量很大时，会击垮数据库
- 悲观锁解决一人一单
  - 缺点：并发量低
#### 异步秒杀：（redis预扣库存 + mq）
异步核心：优先处理主要任务（下单+扣库存），异步处理次要任务（发放优惠券，增加积分）
- 1\. 提前将商品放入缓存（预热）
- 2\. 判断用户是否已下单（一人一单）
  - 使用redis的set来存储用户和优惠券id
- 3\. redis预扣库存
  - redis原子操作扣库存
  - 库存扣完了将活动标志为已结束（防止后续无效请求）
- 4\. 预扣成功则将下单消息提交到mq
- 缺点：redis宕机后无法下单
  - 方案：
    - 提高redis可用性
    - redis哨兵，redis持久化策略
    - 消息队列的高可用
    - 降级（多级缓存）
    - 限流


## 消息队列
### 在哪用了MQ
- 秒杀的异步操作
- redis和数据库一致性

### 具体实现异步秒杀的步骤
- 1\. 用户发起请求：
  - 调用lua脚本，将优惠券id和用户id作为参数传入
  - lua脚本在redis中执行：判断库存是否充足 + 是否已下单。 成功则扣库存并记录下单信息
- 2\. 消息生产：
  - 生产者将订单信息作为消息发送到 Kafka 中。
  - 此处需要指定主题（topic）和分区（partition）。Kafka 支持基于 消息键（如用户 ID 或订单 ID）来决定消息的分配策略，确保相同的消息键会发送到同一个分区。
- 3\. 消息消费：
  - 专门设置消费者模块：
    - 消费者会先根据订单信息中的用户 ID 和优惠券 ID 进行数据库查询，判断用户是否已经购买过该优惠券。
    - 如果没有购买过，消费者会调用库存扣减服务，扣减相应优惠券的库存。
    - 如果库存扣减成功，消费者会将订单信息保存到数据库中。

### kafka为什么高性能
- 批量操作，减少交互
- 消息压缩
- 顺序写
- 利用page cache，优先从page cache读取，生产消费速率接近时可做到不落盘
- 零拷贝（kafka使用sendfile()和mmap）
  - sendfile()是直接跳过用户空间，流程变为了 磁盘 -> PageCache（内核）, PageCache（内核） -> socket缓冲区（内核） -> 网卡
  - 进入用户空间是为了让用户进行数据修改，而消息队列是为了消息传输，如果要修改可以在生产和消费时进行，而不必在传输过程中进行
  - 其实就是为了保证传输的高效
  - Producer生产的数据持久化到broker，采用mmap文件映射，实现顺序的快速写入；
  - Customer从broker读取数据，采用sendfile，将磁盘文件读到OS内核缓冲区后，直接转到socket buffer进行网络发送。

### kafka为什么不支持读写分离
- 数据一致性问题
- 延迟问题（尤其是kafka涉及到磁盘，需要的延迟更长）
- 架构简单

### rocketMQ的分布式事务
- 使用 半消息 + 事务回查 的机制
- 半消息是先向rocketMQ服务器发消息，再本地执行事务，事务执行完通知服务器提交或回滚
- 分布式事务中，消息和事务是分开执行的，需要保证原子性。
- 因此，使用半消息就保证了：业务成功了，消息也一定到了mq并且可消费。

### 为什么使用消息队列而不用线程池做异步？
- 分布式，跨进程
- 解耦
- 持久化
- 任务丢失风险
- 高可用
- 可重试
- 削峰
- 重试机制

### 消息幂等？
- 出现原因：
  - 网络波动导致消息已被消费但消费者未提交offset
  - MQ异常重试
- 解决方案：
  - 每条消息设置唯一id，消息处理完进行保存（redis的set操作 或 数据库自增）。处理时检查id是否被出处理过
  - 分布式锁：确保每条消息只有一个消费者进行处理

### 补偿机制？
- 为什么需要（分布式系统或高并发场景下，数据的一致性难以保证）：
  - 消息丢失：Kafka / RabbitMQ 消息消费失败
  - 超时异常：秒杀优惠券预扣成功，但订单未支付
- 解决方案：
  - 1\. 事务型补偿：如使用tcc，里面的cancel就可以在失败时回滚
  - 2\. 消息队列的补偿：mq消费失败是重试或将消息放入死信队列，再开启定时任务扫描死信队列，人工补偿

### 消息堆积怎么解决？
- 原因：
  - 生产速率 > 消费速率
  - 消费者故障
  - 队列长度有限制
  - 消息处理时间过长
- 解决方案：
  - 修改消费端程序，让其将收到的消息快速转发到其他topic(可以设置很多分区)，然后再启动多个消费者同时消费新主题的不同分区。
  - 增加消费者实例（注：kafka中消费者数量不能超过 topic 的分区数，因此还需要增加分区）
  - kafka集群，增加容量
  - 批量消费，减少数据库或外部 API 的调用次数
  - 优化消息处理逻辑，如减少不必要的数据库操作（使用缓存），异步处理非核心逻辑
  - 流控（限流 + 拒绝）

### 使用线程池消费mq的消息时，异步数据持久化的线程池参数应该怎么设计？
#### 参数设计
在秒杀场景下，线程池消费mq的消息并更新数据库，是IO密集型（与数据库交互），所以：
- 核心线程数：CPU数量 * 2（或更多）
- 最大线程数：不超过数据库最大连接数
- 线程存活时间：30s
- 任务队列：使用了零容量的SynchronousQueue，一进一出，避免队列里缓冲数据，这样在系统异常关闭时，就能排除因为阻塞队列丢消息的可能。
- 拒绝策略：可以使用CallRunsPolicy，避免消息丢失

#### 流程设计1（以下是基于 有顺序性 要求的）
- kafka多分区 + 线程池多线程消费，同时，同个订单id放到同个分区，并且每个线程只消费一个对应的分区（这样就能保证有序性）。


#### 流程设计2（以下是基于 无顺序性 要求的）
- 在kafka分区无法再增加，我们也不需要顺序性的前提下，我们可以在流程设计1的基础上，将 一个线程消费一个分区 变为 多线程消费同一个分区。
- 线程池是多线程消费，虽然我们不要求顺序性，但是kafka为了安全性考虑，如果先执行后commit会导致kafka拒绝你调用它的api进行消费。
- 因此此处采取的做法是先commit再执行消费动作，但是这样会导致消息丢失（漏读）的问题。所以我们还需要补偿机制，开启定时任务，在业务低峰期做数据兜底。
- 但是这样提前ack，如果系统异常关闭还是有丢失风险，我们要两手保证。所以在commit之前将消息写入日志，这样当系统重启之后能从日志中重新读取。
- 相较于日志，redis 效率高 + 使用方便 的优点，其实是由于日志的。
  - 通过redis缓存消息，使用Hash结构，提交任务的同时写入Redis，任务执行完毕删掉这个值，那么剩下的就是出现问题的消息。
  - 在系统启动时，首先检测一下redis中是否有异常数据。如果有，首先处理这些数据，然后正常消费。
- 总结：多线程是为了增加效率，redis等是为了增加可靠性。

#### 线程池监控
ThreadPoolExecutor提供了 beforeExecute, afterExecute, terminated 等方法，我们可以继承线程池并重写方法来监控任务执行过程

## 点赞
使用redis的zset实现
- zset的key是blogId，value是userId，score是用户点赞时间
- blog中设置isLiked字段，每次查询blog时判断当前用户是否点赞过（在zset中查），并给isLiked赋值
- 显示blog的点赞用户列表时根据zset获取用户，从而实现按点赞时间对用户列表排序

## 好友关注
- 数据库设计：
  - tb_follower表，记录当前用户关注的人
- 共同关注：
  - 使用redis的set集合，当用户关注时


## 项目面试题
### 订单幂等性怎么做的？
即：post请求带着：一个用户id，一个优惠卷id。发送多次请求，如何保证只有一个成功？  
答：
- 1\. 基于唯一业务id：
  - 订单请求携带一个唯一的业务 ID
  - 服务端处理前先检查 Redis ，如果该 orderNo 已存在，则直接返回结果，防止重复创建订单
- 2\. 基于数据库唯一约束：
  - 在订单表中，给订单id创建唯一索引
- 3\. 基于分布式锁：
  - userId 加 Redis 分布式锁，防止同一用户短时间重复提交订单

### 你库存扣减之后，还要去insert一个新的订单，你是如何保存这个的一致性的？
- 方案一： Redis + MQ 方案，实现的是最终一致性（容忍短暂不一致）
  - redis原子操作decr扣库存
  - 异步发送订单消息到mq
  - 消费时，若插入失败，则进入死信队列或重试机制
  - redis补偿机制：数据库插入失败时，要回滚redis库存
- 方案二： TCC分布式事务（保证严格一致性，如银行支付） -> Seata 阿里巴巴开源框架
  - Try（预扣库存）：尝试将各个服务的状态修改为中间态：
    - 订单服务：将订单状态修改为 OrderStatus.UPDATING，表示正在修改。
    - 库存服务：提供 reduceStock() 接口，不直接扣减库存，而是冻结库存。
    - 积分服务：提供 addCredit() 接口，不直接增加会员积分，而是先在积分表里的一个预增加积分字段中加入积分。
  - Confirm（确认订单）：插入订单数据库，确认库存扣减成功后，将 Try 阶段的中间态修改为最终状态。
  - Cancel（回滚操作）：如果订单失败，将状态回滚至最初状态。
  - 具体文章：https://geekdaxue.co/read/qingyubailou@gygiq6/lgga0u5nxhhncbe1
- 方案三： RocketMQ的分布式事务 -> 半消息机制 + 事务回查
  - 缺点：依赖RocketMQ、需要事务回查会增加网络延迟、代码侵入高要手动实现事务逻辑

### （和上一问类似）如何保证缓存和数据库的一致性？
- 1\. Cache Aside（先更新数据库，再删除缓存）
  - 适合读多写少
  - Cache Aside仍然存在一定问题，如并发写操作，可以使用延迟双删
  - 为了保证删除一定成功，在删除失败后加入MQ，由消费者重试删除操作
- 2\. Redis + MQ（先操作缓存，再更新数据库）
  - 适合高并发（秒杀扣库存）
  - 注意消息幂等，保证消息最终一致性
- 3\. 双写策略（同时操作缓存和数据库）
  - 适合强一致性场景（如金融交易）
  - 使用分布式事务，如TCC
- 4\. 延迟回写（只操作缓存，开启延时任务定期回写数据库）
  - 适合点赞业务，操作频率高，且对一致性延迟的要求低


### 项目为什么要加消息队列？
- 削峰填谷
- 异步
- 解耦
- 可靠性

### 抢优惠券没有及时处理怎么办？
先通知用户已经抢到了，后面mq保证最终一致性

### 抢优惠券处理完了如何通知用户？
消费者异步处理完订单后，通过websocket通知客户
- websocket
  - HTML5开始提供的一种浏览器与服务器间进行全双工通讯的网络技术。可以实现客户端和服务器端的长连接，双向实时通信。
  - 特点：异步、事件触发，数据格式轻量，性能开销小，通信高效
  - 缺点：服务端维护很多长连接会耗费资源
- 轮询（客户端定时向服务器发起查询请求）：
  - 大厂普遍做法，如腾讯PC端微信扫码登录、京东商城支付成功通知
  - 轮询不是更耗时吗？其实不是，轮询是不可能穿透到后端数据库查询服务的，比如秒杀，一个缓存标记位就可以判定是否秒杀成功。

### 说说你的关注模块数据结构怎么设计的？我关注的人和关注我的人怎么设计的？
- 1\. mysql数据库表：
  - tb_follower
    - 主键：自增id
    - user_id：谁去关注别人（粉丝）
    - followee_id：被关注的用户（博主）
    - 唯一索引(user_id, followee_id) 确保一个人不能重复关注同一个人
- 2\. redis（用于加速查询）：
  - Set1： 存储用户关注的 ID 列表
  - Set2： 存储用户的粉丝列表

### 那种大v，粉丝数量应该很多，这种热key+大key你是怎么处理的？分表知道吗？
- 解释热key和大key：
  - 热 Key：指的是在某些时段内频繁访问的键，通常是热门用户、热门帖子、热门评论等。
  - 大 Key：指的是一个存储大量数据的键，例如一个用户关注的所有粉丝存储在一个 Set 中，如果一个大 V 拥有几百万个粉丝，那么 Redis 的 Set 就会变得非常大。
- 负面影响：
  - 热 Key：请求阻塞 + 响应时间延长 + CPU占用率高
  - 大 Key：内存不足 + 操作耗时（处理时间 和 网络传输延迟）
- 解决方案：
  - 热key：
    - 缓存预热
    - 热点数据分片（分到不同redis实例上）
  - 大key：
    - 大key 进行拆分为多个 小key
    - 定期对 大key 进行清理（异步清除）
    - 合理的缓存时间

### 我假如关注一个人之后，马上要给他发消息怎么办（场景：互关才能发消息），你怎么保证这个即时性？

### 简述你的登录逻辑
- 1\. 用户输入手机号请求验证码（格式校验，前端+后端），后端生成验证码并发送短信，验证码存在redis
- 2\. 用户输入验证码并提交，后端验证是否匹配
- 3\. 服务器验证成功后，生成jwt，存储用户信息在thread local，返回给客户端
- 4\. 用户将jwt存在LocalStorage，下次登录会携带jwt
- 5\. 登录状态校验：验证签名和过期时间，通过则授权
- 6\. 超时刷新：双拦截器实现，第一个拦截器拦所有页面用于刷新，第二个用于拦部分需要用户权限的页面用于校验

### 为什么要用thread local？thread local底层你懂吗？会出现什么问题？内存泄漏怎么解决？
- 为什么要用ThreadLocal？
  - 线程隔离：在多线程的情况下，如果你不想用同步的方式解决就可以用ThreadLocal线程本地变量来解决并发的问题。
  - 减少查询：传统方法每次用户查询都要到数据库，现在可以在请求生命周期内缓存用户信息，避免重复查询。
  - 简化代码：减少参数传递。
- 在哪一步用到？
  - 在拦截器中拦截用户请求并取出其中的jwt，每次解析的时候将jwt中的用户信息存入ThreadLocal，然后在后续的方法里面随时随地的获取当前用户信息了。
- thread local底层？
  - 每个线程维护一个ThreadLocalMap，它的key 是 ThreadLocal 实例，value 是具体存储的对象。这个map仅属于当前线程。
- 会出现什么问题？
  - 内存泄漏：
  - 线程池问题：ThreadLocal仅适用于短生命周期线程，而线程池会复用线程，如果不清理会造成脏数据
- 解决内存泄漏？
  - 用完后在finally代码块中调用remove方法，显式释放
- 其他注意事项？
  - 不适合存储大数据，因为生命周期和线程绑定，存大数据会给GC很大压力
  - 不适合跨线程传递数据

### 项目的拦截器详细讲讲
- 1\. 权限刷新拦截器（token续期）
  - 作用：jwt有效期内刷新jwt
  - 注意：jwt续期最好不要重新签发（jwt是一次性的），而是将jwt存到redis，并设置过期时间
  - redis存jwt的结构：
    - key: jwt
    - value: 过期时间
  - 刷新时机：
    - 暴力刷新（每次请求都刷新）、轮询刷新
    - 快过期前10分钟刷新（问题：可能有人在之前一直浏览，但过期前10分钟不浏览导致没有刷新）
  - 存在问题：
    - JWT的无状态是会话完全交给客户端来管理，但在处理修改密码及退出时却又必须使后端修改状态，势必会使服务弱依赖于redis。
    - 这样设计，依赖于redis，跟cookie+session无异（不过多节点部署的session也需要redis这个第三方）。
    - 所以jwt若想真正受益于无状态，还是应当用在类似于第三方授权这种一次性的鉴权场景中。
- 2\. 登录校验拦截器（身份校验）
- 3\. 限流拦截器（防止秒杀过快）
  -  Redis+滑动窗口限流 或 令牌桶算法
    - redis滑动窗口限流： key是请求ip value是请求次数 ex是超时时间 当还未超时的时候，value请求参数超过一定值就返回 "429 Too Many Requests"

### redis + token 和 JWT 两个方案优劣？
有状态：
- 优点：
  - 1. 


### 布隆过滤器实现？ 布隆过滤器满了怎么办？ 布隆过滤器的数据怎么迁移？ 从一个小的变成一个更大的布隆过滤器可以吗？
- 实现：使用redisson提供的RBloomFilter
  - 基于redis，支持分布式
  - 自动扩容
  - 线程安全
  - 支持集群
- 满了怎么办：
  - RBloomFilter支持自动扩容（其实是创建新的布隆过滤器）
  - 可以使用多个布隆过滤器
  - 定期重建

### 旁路缓存 和 延迟双删？更新成功但是第二次删除失败了怎么办？
- 旁路缓存：
  - 写操作？
    - 先更新数据库，再删缓存
  - 为什么是删缓存而不是更新缓存？
    - 如果缓存的结构是一个hash或list等，更新数据时需要遍历，比较耗时
- 旁路缓存 和 普通双删 有什么问题？
  - 旁路缓存：
    - 问题1：在更新数据库的时候，其他的读请求只能拿到旧数据（短时间内数据不一致）
    - 问题2：极端情况下，初始缓存为空，先有读请求，在读请求中间发生写请求，且删除缓存操作快于读请求的写回操作，最后缓存中是旧值（概率很低）
  - 普通双删：在第一次删到更新之前，有一个读请求（发现缓存空则去查数据库的旧数据），在第二次删后，读请求写回旧数据 -> 解决方案：延迟双删
- 延迟双删：
  - 第二次清空缓存之前，多延时一会，等读请求写回旧数据结束了再删
  - 问题：第一次删除缓存到更新之前，还是会有读到旧数据的情况（短暂不一致）
  - 优点：操作简单，直接删除缓存和更新数据库，逻辑清晰。
  - 缺点：在高并发场景下容易出现数据不一致的问题。
- 关于短暂不一致：
  - CAP理论说明了，在分区容错性的前提下，可用性和一致性不可兼得，如果需要数据库和缓存数据保持强一致，就不适合使用缓存。所以使用缓存提升性能，就是会有数据更新的延迟。
- 第二次删除缓存失败？
  - 后果：删除失败会导致脏数据
  - 解决办法： 删除缓存重试机制
  - 流程：
    - 1\. 缓存因为某些原因，删除失败
    - 2\. 把删除失败的key放到消息队列
    - 3\. 消费消息队列的消息，获取要删除的key
    - 4\. 重试删除缓存操作
    - 5\. 重试失败多次，向业务层报错

### 旁路缓存机制具体解决的什么场景？
- 商铺详情页查询 （减少无用的数据库查询，同时提升性能）

### 更新缓存失败了怎么办？
- 重试：见上上问（mq）

### 完整的缓存更新策略的流程？
Cache-Aside + 延迟双删 + 异步重试 + Binlog监听

#### 写操作流程
- 1\. 删除缓存（第一次删除）
  - 目的：防止后续并发读请求命中旧缓存。
- 2\. 更新数据库
- 3\. 延迟双删（第二次删除）
  - 目的：延迟时间需覆盖“其他线程可能读取旧数据并回填缓存”的时间窗口。
- 4\. 异步重试机制
  - 若第一次或第二次删除缓存失败，将删除操作提交到消息队列（如Kafka），由消费者异步重试，直至成功。
  - 关键点：消费者需实现幂等性

#### 读操作流程
- 1\. 读取缓存命中，直接返回数据
- 2\. 缓存未命中时，查询数据库并回填缓存，回填时加分布式锁（防止多个线程并发回填相同数据）

#### Binlog监听（兜底一致性）
- 1\. 使用Canal监听MySQL的Binlog日志，捕获所有数据变更
- 2\. 发布变更事件到Kafka，保证事件不丢失
- 3\. 消费者处理事件
- 原理：
  - 伪装成MySQL的slave，向主节点请求同步，得到dump的binlog增量日志，同时有ack机制保证正常消费

#### 如果需要缓存和数据库强一致性，那么需要 同步写（如Write-Through）+ 分布式事务

### 项目架构？
重点是秒杀
#### 上游
- 功能：流量入口 & 请求控制层
- 目标：削峰、限流、快速响应，避免下游崩溃
- 模块：
  - 用户请求（前端、APP）： 接入层优化（CDN、本地缓存）
  - 网关（Nginx、API Gateway）： 限流策略（滑动窗口、令牌桶等）
  - 限流层（Redis+Lua 限流）： 单用户限流、全局限流
  - 缓存层（Redis 预扣库存）： 库存预热，避免直接查数据库
  - 消息队列（MQ 入口）： 解耦流量、削峰（使用 Kafka）
- 优化重点：
  - 限流
  - 快速失败（秒杀失败直接返回，尽量避免请求进入下游）
  - 缓存预扣库存：减小数据库写入压力
#### 下游
- 功能：订单 & 支付 & 物流等业务处理层
- 目标：保证数据一致性、可靠性，确保最终下单成功
- 模块：
  - 消息队列（MQ 消费者）：使用线程池提高消费速度
  - 订单服务（MySQL）：订单分库分表，提升吞吐量
  - 支付服务（支付宝/微信支付）：采用 异步支付回调
  - 库存回滚（Redis+DB）：任务调度（如 Redis 事务）
  - 短信/通知系统：异步发消息给客户，不影响主流程
- 优化重点：
  - 高效消费 MQ：使用线程池提高吞吐量，防止消息堆积。
  - 订单写入优化：数据库采用分库分表 + 事务补偿，防止热点写入。
  - 异步化处理：支付、通知等任务异步执行，降低响应时间，同时增加重试机制，保证数据最终一致性。

### 用户在消息堆积时以为卡了多次请求怎么处理？
前端阻止请求

### 秒杀场景下扣减库存太慢了怎么办?
- mysql数据库扣减慢：
  - 数据库集群
  - 分库分表
  - 索引优化
- redis扣减慢：
  - Redis热key，大key




