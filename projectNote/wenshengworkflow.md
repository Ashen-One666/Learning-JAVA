# mcp
## mcp通信协议选择
注：服务器必须公开一个支持 POST 和 GET 方法的 HTTP 端点（称为 “MCP 端点“）
### HTTP+SSE 的存在的问题：
- 长期使用连接资源
- 资源消耗高（长连接在高并发下消耗显著）
- 连接的可恢复性差
### Streamable HTTP 优势：
- SSE 是单向的，服务器必须提供两个端点：
  - SSE GET 端点，供客户端建立连接并从服务器接收信息
  - 常规 HTTP POST 端点，供客户端向服务器发送 JSON-RPC 消息
- 可以直接返回响应，并复用同一个 TCP 连接处理多个请求，其 TCP 连接数最多仅达到几十个
- 平均响应时间更短
- 同时支持无状态和有状态服务

### 为什么不用websocket
![为什么不用websocket.png](images%2F%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E7%94%A8websocket.png)

### SSE 和 Streamable HTTP对比：
![sse和streamhttp对比.png](images%2Fsse%E5%92%8Cstreamhttp%E5%AF%B9%E6%AF%94.png)

## MCP server设计
### Resources 和 Tools 的设计
#### Resources
服务于我们的文生workflow项目，即：仅返回工具的名称、入参、出参、介绍，无需对工具进行调用
- 目前做法：写死在server代码中，静态工具清单的方式存储（dict结构）
- 未来改进措施：写在数据库中，server启动时进行动态注册

#### Tools
服务于其他可能调用我们MCP server的client，提供工具调用能力


# 预测面试题
## 问1： 简单介绍一下项目架构
### 一、项目背景
在实习中，我们面临的核心问题是：
- 华为云放大镜平台每天会产生大量网络告警。
- 传统告警处置依赖人工值班和脚本，根因分析耗时，告警处置流程平均需要 15 分钟左右。
- 我们希望引入大模型（DeepSeek-V3）来辅助根因分析，并自动生成可落地的处置工作流，缩短告警恢复时间。

### 二、项目链路
- 1\. 工作流生成链路（离线 / 准备阶段）
  - 输入：专家知识库 + MCP 提供的工具集。
  - 处理流程：
    - 1.1 大模型结合告警处理指南，选择合适工具集。
    - 1.2 生成 PlantUML 表示工具调用关系。
    - 1.3 转换为 DSL 工作流描述。
    - 1.4 将 DSL 适配转换为 Agent Builder 平台所需的 JSON 格式。
    - 1.5 上传至 华为云 Agent Builder 平台。
  - 结果：平台上预先存储了一批可执行的标准工作流。

- 2\. 告警处置链路（在线 / 触发阶段）
  - 输入：实时告警（来自放大镜平台）。
  - 处理流程：
    - 2.1 放大镜平台检测到告警，调用 Agent Builder 平台上对应的 工作流。
    - 2.2 工作流驱动实际 API 调用（例如拉取日志、重启服务、下发配置）。
    - 2.3 处置结果返回，并展示在放大镜平台的 “AI 建议” 栏。
  - 结果：SRE 可以直接参考或执行 AI 建议，缩短告警闭环时间。

~~### 二、整体架构分层~~
整体架构可以分为 输入层 → 智能处理层 → 执行层 → 优化反馈层 四个部分。
- 1\. 输入层（告警采集）
  - 告警源：华为云网络设备产生告警，统一汇聚到放大镜平台。
  - 告警数据：包括设备信息、时间戳、告警内容、历史上下文。
  - 数据入口：经过消息总线（Kafka）和预处理模块，统一转发给 AI Agent。

- 2\. 智能处理层（AI Agent）
这是整个系统的核心，包含三个子模块：

  - ① MCP Client/Server 与工具注册
    - 通过 MCP 协议统一管理工具，Server 提供工具清单，Client 根据模型请求调用工具。
    - 工具包括 API 查询、配置修改、日志检索等。

  - ② 多轮 Prompt 驱动的工作流生成
    - 第一轮：工具集选择（大模型根据告警类型，决定需要用哪些工具）。
    - 第二轮：PlantUML 生成（把工具调用关系转为图结构）。
    - 第三轮：DSL 转换（将图结构转为可执行 DSL，上传到 Agent Builder 平台）。

    - ③ 异常修复模块
      - 基于消息队列监听执行异常。
      - 使用 DFS 遍历 Workflow 节点，结合大模型判断失败原因，尝试自动修复或兜底重试。
      - 失败多次则触发人工介入。

- 3\. 执行层（Agent Builder 平台）
  - 将 DSL 工作流部署到华为云 Agent Builder 平台，由平台调度实际 API 调用。
  - 确保每个步骤都有可执行的接口（Mock 校验提前保证接口正确性）。
  - 支持流程监控与状态追踪。

- 4\. 优化反馈层（持续优化）
  - 定时分析运行日志，识别耗时步骤。
  - 通过 few-shot 提示词优化、Mock 服务校验、模型反思机制，迭代生成新版本工作流。
  - 将新旧版本工作流进行对比（耗时、正确率），择优更新。

### 三、效果
- 收集 2w+ 告警样本，评估 召回率、参数解析、逻辑跳转 等指标。
- 覆盖大部分常见告警场景。
- 最终将告警处置流程由 15 分钟缩短到约 11 分钟，显著提升处理效率和自动化率。


## 问2： 项目最大的挑战是什么
答：是如何保证工作流的稳定性。这个我主要分成两个层面来做：
- （1）生成阶段的稳定性保障
  - 问题：大模型直接生成的工作流，可能存在 api 召回错误、参数错误、逻辑跳转不合理，生成的语法不符合要求。
  - 做法：
    - 1.1 代码校验：
      - 使用 **Mock 服务** 模拟工具调用，验证入参出参类型是否与 MCP 注册的 schema 一致，避免参数错配。
      - 使用 **DFS 校验** 工作流结构，确保没有孤岛节点，且所有依赖入参都来自前序节点的出参，避免空变量引用。
    - 1.2 大模型反思机制：
      - 在生成时通过 **few-shot 样例** 和 **注意点强调** 引导模型保持链路完整。
      - 在生成后让模型进行 **自检**，将跳转逻辑与 **告警指南原文** 比对，若不一致则标注并修正。

- （2）执行阶段的修复机制
  - 问题：即使生成阶段没问题，工作流在实际执行中仍可能失败，例如 API 超时、设备状态不一致，或者运维人员反馈结果不符合预期。
  - 做法：
    - 2.1 我在放大镜平台调用失败时，通过消息队列捕获异常日志。
    - 2.2 然后由大模型对失败步骤进行定位和修复：结合 DFS 遍历工作流节点，逐一排查问题并尝试修改参数或替换工具。
    - 2.3 如果多次修复无效，再触发人工介入。  

## 问3： MCP 协议与工具注册？


## 问4： 多轮 Prompt 模板，分为工具选择、PlantUML 生成、DSL 转换三个阶段，能分别举个例子说明吗？
1. **设置身份**
  - 明确告诉模型它的角色，例如：  
    “你是一名网络运维专家，擅长根据告警处理指南选择合适的工具脚本。”

2. **说明目标**
  - 指定任务目的，例如：  
    “根据告警指南，从已有工具集中进行 API 召回，输出所需工具及调用顺序。”

3. **给出 Few-shot 示例**
  - 提供 2~3 个示例，让模型模仿格式和逻辑：
  - 输入：告警 = “链路抖动”，工具集 = [Ping 检测, 日志检索]
  - 输出：先调用 Ping 检测 → 若异常再调用日志检索。

4. **强调注意点**
  - 对关键点进行限制，避免模型产生幻觉或偏离规范：
  - 例如：
    - 选取的 API 必须来自提供的工具集，不能编造。
    - 保证参数名称、输入输出类型与 MCP 注册时一致。
    - 保持工具调用顺序与告警指南逻辑一致。

## 问5： 你们实现了异常修复模块，基于消息队列消费异常任务，结合 DFS 遍历和模型判断修复逻辑。能具体讲讲这里的流程吗？
1. **异常捕获**
  - 工作流在 Agent Builder 平台执行时，若某一步骤失败（如 API 超时、参数错误、工具不可用），会把失败任务投递到消息队列。
  - 我们的异常修复模块从消息队列中消费这些失败任务，作为输入。

2. **DFS 遍历工作流**
  - 对失败任务对应的工作流进行 **DFS 遍历**，逐个检查节点：
    - 确认当前失败节点的前序依赖是否正常。
    - 检查输入参数是否为空值或不合法。
    - 判断工具调用是否存在超时/格式不匹配等问题。

3. **大模型诊断与修复**
  - 把失败的上下文（告警信息 + 节点参数 + 错误日志）输入给大模型。
  - 让模型判断可能的失败原因，并给出修复方案：
    - 参数修正（如默认值替换、字段格式调整）。
    - 工具替换（用等价 API 替代）。
    - 步骤调整（跳过冗余步骤，直连后续步骤）。

4. **重试与兜底**
  - 修复后的工作流重新执行。
  - 若仍失败，则允许有限次数的兜底重试。
  - 多次失败仍未解决 → 标记任务并触发人工介入。

5. 补充：异常日志设计
（1）JSON 形式存储  
（2）参数设计：  
alarm_id（告警ID）、workflow_id（工作流ID）、step_id（步骤ID）、tool_name（工具名）、input_params（输入参数）、
actual_output（实际输出）、error_type（错误类型）、error_message（错误信息）、timestamp（时间戳）、retry_count（重试次数）、trace_id（全链路追踪ID）。

## 问6： 你们怎么验证新工作流比旧工作流更优？有没有做灰度发布或 A/B Test？

## 问7： 你们收集了 2w+ 告警数据，测试指标包括 API 召回率、参数解析、逻辑跳转准确性。能分别讲讲这些指标是如何设计和计算的？

## 问8： 如果在生产环境中大模型 API 响应延迟增加，导致告警 Workflow 执行变慢，你会怎么排查？

## 问9： 飞书作为大规模 SaaS 系统，每天有大量告警事件，如果大模型推理耗时很长，你觉得有哪些优化思路？



